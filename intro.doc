{div open id="intro"}

{{:https://computation.llnl.gov/casc/sundials/main.html}Sundials} is a
collection of six numeric solvers: CVODE,  CVODES, IDA, IDAS, ARKODE,
and KINSOL.
It is written by Carol S. Woodward, Daniel R. Reynolds, Alan C. Hindmarsh,
and Lawrence E. Banks at the {e Center for Applied Scientific Computing,
Lawrence Livermore National Laboratory} with significant contributions from
Radu Serban, and contributions from Peter N. Brown, Scott Cohen, Aaron Collier,
Keith E. Grant, Steven L. Lee, Cosmin Petra, Dan Shumaker, and Allan G. Taylor.

This OCaml interface was written by {{:http://www.tbrk.org}Timothy Bourke}
({{:http://www.inria.fr}Inria}/{{:http://www.di.ens.fr/}ENS}),
{{:https://sites.google.com/site/juninoueprofessional/}Jun Inoue}
({{:http://www.aist.go.jp/index_en.html}AIST}),
and
{{:http://www.di.ens.fr/~pouzet/}Marc Pouzet}
({{:http://www.upmc.fr/}UPMC}/{{:http://www.di.ens.fr/}ENS}/{{:http://www.inria.fr/}Inria}).
It provides a complete OCaml interface to Sundials version {b {var version}}.

The source code is available under a New BSD license at
{{:https://github.com/inria-parkas/sundialsml}git\@github.com:inria-parkas/sundialsml.git}.
{{:mailto:tim\@tbrk.org}Feedback},
{{:https://github.com/inria-parkas/sundialsml/issues/new}bug reports},
and {{:https://github.com/inria-parkas/sundialsml/compare}pull requests}
are welcome.
Support requests should be made to the (public)
{{:mailto:caml-list\@inria.fr?subject=Sundials/ML:}OCaml mailing list}.

{3:contents Contents}
{ul
    {- {{:#overview}Overview}}
    {- {{:#api}API Reference}}
    {- {{:#install}Installation}}
    {- {{:#running}Running programs}}
    {- {{:#performance}Performance}}
    {- {{:#refs}References}}
    {- {{:#acks}Acknowledgements}}
    {- {{:#indexes}Indexes}}
}

{2:overview Overview}

The structure of this interface mostly follows that of the original library,
both for ease of reading the existing documentation and for converting
existing source code, but several changes have been made for programming
convenience and to increase safety, namely:
- solver sessions are mostly configured via algebraic data types
  rather than multiple function calls;
- errors are signalled by exceptions, not return codes
  (also from user-supplied callback routines);
- user data is shared between callback routines via closures (partial
  applications of functions);
- vectors are checked for compatibility (using a combination
  of static and dynamic checks); and
- explicit free commands are not necessary since OCaml is a garbage-collected
  language.

Functions have been renamed according to a regular scheme. Leading {e
module identifiers} are replaced by module paths, words
beginning with an uppercase letter are separated by underscores and put
into lowercase. For instance, [IdaSetErrHandlerFn], becomes
{!Ida.set_err_handler_fn}, and [CVSpilsSetJacTimesVecFn] becomes
{!Cvode.Spils.set_jac_times_vec_fn}.

Constants are replaced by variant types in most cases. They are renamed by
conversion to {e CamlCase} and the removal of underscores. For instance,
[PREC_NONE] becomes {{!Spils.preconditioning_type}Spils.PrecNone}.
Exception names are sometimes renamed for consistency and to make them more
self explanatory.
For instance, the return codes [CV_FIRST_RHSFUNC_ERR] and
[IDA_FIRST_RES_FAIL] become, respectively, the exceptions
{!Cvode.FirstRhsFuncFailure} and {!Ida.FirstResFuncFailure}, and [CV_BAD_IS]
becomes {!Cvodes.Sensitivity.BadSensIdentifier}.

Rather than try to duplicate or replace the comprehensive
{{:https://computation.llnl.gov/casc/sundials/documentation/documentation.html}
Sundials user manuals}, this documentation provides brief summaries,
adapted from the manual, with hyperlinks back to the original text whenever
possible (the original HTML documentation is not currently being updated).

{3:nvector Nvectors}

Sundials defines an abstract interface for vectors and provides default
serial, parallel, pthreads, and openmp instantiations.
The OCaml interface defines likewise a generic
{!Nvector.t} type whose type arguments indicate the underlying {e
data} and {e kind}—the latter may be {!Nvector_serial.kind},
{!Nvector_parallel.kind}, or {!Nvector_custom.kind}.
The {!Nvector.unwrap} function gives direct access to the underlying data.

The interface to serial nvectors, {!Nvector_serial}, is based on
{{:http://caml.inria.fr/pub/docs/manual-ocaml/libref/Bigarray.html}Bigarrays}.
These arrays are manipulated directly, i.e., with no additional overhead,
within the solver by the original low-level serial nvector operations
(see {!Nvector.NVECTOR_OPS}).
The same low-level operations can be called from OCaml
({!Nvector_serial.Ops}), as can equivalent reimplementations in OCaml on the
underlying data ({!Nvector_serial.DataOps}).

The interface to parallel nvectors, {!Nvector_parallel}, is based on
{{:http://caml.inria.fr/pub/docs/manual-ocaml/libref/Bigarray.html}Bigarrays}
and the {{:https://forge.ocamlcore.org/projects/ocamlmpi/}OCamlMPI}
library. Parallel nvectors are only available when Sundials/ML is configured
to use MPI, as described {{:install}below}.

Pthreads nvectors, {!Nvector_pthreads}, and openmp nvectors, {!Nvector_openmp},
are essentially serial nvectors whose underlying operations are executed by
multiple threads.

Besides these four standard implementations, it is also possible to define
new nvector implementations through {!Nvector_custom} by providing low-level
operations on an underlying datatype. A demonstration of this feature on
float arrays is provided in {!Nvector_array}. Custom nvectors suffer two
disadvantages compared to the standard nvector implementations. First, each
low-level operation incurs the cost of a callback into OCaml. Second, of all
the provided linear solvers, only {!Cvode.Diag} can be used; although
custom solvers can be implemented via {!Cvode.Alternate},
{!Ida.Alternate}, and {!Kinsol.Alternate}.

{3:linsolv Linear Solvers}

Nonlinear algebraic systems occur optionally in the solution of ODE initial
value problems with {!Cvode}, invariably when solving DAE initial value
problems with {!Ida}, and when solving implicit problems or problems
involving a mass matrix with {!Arkode}, and directly in the problems treated
by {!Kinsol}. Such systems are solved using some form of Newton iteration
which in turn requires the solution of linear equations.

Sundials provides six options for the solution of linear equations:
{ul
    {- The {e diagonal approximation} of Jacobians by difference equations (only
    for {!Cvode});}
    {- {e Direct Linear Solvers (DLS)} requiring user-supplied callback
    functions that explicitly compute a Jacobian;}
    {- {e Scaled Preconditioned Iterative Linear Solvers (SPILS)}
    requiring user-supplied callback functions to setup and solve
    linear preconditioning systems;}
    {- {e The SuperLU_MT sparse-direct linear solver} requiring a
    user-supplied callback function that computes a sparse Jacobian;}
    {- {e The KLU sparse-direct linear solver} also requiring a
    user-supplied callback function that computes a sparse Jacobian;}
    {- {e Alternate linear solvers} providing hooks for implementing new
    linear solver modules (in OCaml).}
}

The DLS routines are only available to sessions that use serial nvectors.
Callback functions can either update the Jacobian matrix as a
{!Dls.DenseMatrix.t} or a {!Dls.BandMatrix.t}. Access to the underlying
solver routines on bigarrays is provided via {!Dls.ArrayDenseMatrix}
and {!Dls.ArrayBandMatrix}.

The SPILS routines include the {e Scaled Preconditioned GMRES (SPGMR)}, {e
Scaled Preconditioned Bi-CGStab (SPBCG)}, {e Scaled Preconditioned TFQMR
(SPTFQMR)}, {e Scaled Preconditioned Flexible GMRES (SPFMGR)}, and
{e Preconditioned Conjugate Gradient (PCG)} methods.
Additionally, {!Cvode} provides banded preconditioners
for sessions that use serial nvectors. Access to the underlying solver
routines on bigarrays is provided via the submodules of {!Spils}.
Parallel Band-Block-Diagonal (BBD) preconditioners are available to sessions
that use parallel nvectors—see {!Cvode_bbd}, {!Cvodes_bbd}, {!Ida_bbd},
{!Idas_bbd}, and {!Kinsol_bbd}.

The SuperLU_MT and KLU routines are only available to sessions that use
serial nvectors.
Callback functions update the Jacobian matrix as an {!Sls.SparseMatrix.t}.

Each solver module has a distinct linear solver type, e.g.,
{!Cvode.linear_solver} or {!Cvodes.Adjoint.linear_solver}. As for nvectors,
these types are parameterised by data and kind arguments. Values in these
types are constructed by passing parameters to functions like
{!Cvode.Dls.band} or {!Ida.Spils.spgmr}. They are then passed to the
appropriate [init] or [reinit] functions to configure sessions.

{2:api API Reference}

{!modules: Sundials}
{!modules: Dls Spils Sls}
{!modules: Nvector Nvector_serial Nvector_parallel
	   Nvector_pthreads Nvector_openmp
	   Nvector_custom Nvector_array}
{!modules: Cvode Cvode_bbd Cvode_klu Cvode_superlumt
	   Cvodes Cvodes_bbd Cvodes_klu Cvodes_superlumt}
{!modules: Ida Ida_bbd Ida_klu Ida_superlumt
	   Idas Idas_bbd Idas_klu Idas_superlumt}
{!modules: Arkode Arkode_bbd Arkode_klu Arkode_superlumt}
{!modules: Kinsol Kinsol_bbd Kinsol_klu Kinsol_superlumt}

{2:install Installation}

The dependencies of Sundials/ML are
- {{:http://caml.inria.fr/ocaml/}OCaml} {b 3.12.1 or greater},
- {{:http://computation.llnl.gov/casc/sundials/}Sundials} {b {var version}},
- {e Optionally}:
  {{:https://forge.ocamlcore.org/projects/ocamlmpi/}OCamlMPI} {b 1.01}.

Sundials must be compiled with 64-bit floats (the default: {i
--with-precision=double}) and the C compiler must provide 32-bit
[int]s.

When building Sundials manually, we recommend applying the
[sundials-2.5.0.patch] file distributed with Sundials/ML and using
[./configure --enable-examples --enable-shared].  Sundials/ML will
function correctly if the patch is not applied, but the comparison of
examples will fail with incorrect results.

The [configure] script detects and automatically enables optional
features.  Lapack solvers, like {!Cvode.Dls.lapack_dense}, are enabled
if Sundials was built with lapack support.
The {!Sundials.lapack_enabled} value indicates whether these solvers are
available.
The KLU and SuperLU_MT solvers, and the pthreads and openmp nvectors are
enabled if Sundials was built with them.
Parallel nvectors and Band-Block-Diagonal (BBD) solvers
are enabled if Sundials was built with them and OCamlMPI is available.

{3:opam Opam}

Opam is the easiest way to install the library:
{ol
    {- {{:http://computation.llnl.gov/casc/sundials/download/download.php}Download}
        and manually install Sundials (see notes above), or use a
        package manager:
	{ul
	    {- Debian/Ubuntu (without parallelism):
		    [apt-get install libsundials-serial-dev]}
	    {- Mac OS X: [brew install sundials] / [port install sundials]}
	}}
    {- {i Optionally} run [opam install mpi].}
    {- Run [opam install sundialsml].}
}

{3:build From source}

Building from source is a three step process:
{ol
    {- {{:http://computation.llnl.gov/casc/sundials/download/download.php}Download}
        and manually install Sundials (see notes above),
        or use a package manager:
	{ul
	    {- Debian/Ubuntu (without parallelism):
                    [apt-get install libsundials-serial-dev]}
	    {- Mac OS X: [brew install sundials] / [port install sundials]}
	}}
    {- Run [configure] to find and check dependencies.}
    {- Run [make install] or [make install-findlib] to build and
       install the library.}
}

The choices made by the configure script can be influenced by
arguments (like {i --prefix=...}) and variables (like
[OCAMLROOT=...]). Type [configure --help] for detailed information.

OCaml reimplementations of the standard Sundials examples are provided in
the [examples/] subdirectory.
The library's behaviour can be tested via [make tests.opt.log] which runs the OCaml
versions and compares their outputs against those of the original C
versions: they should be identical.
The library's performance can be analyzed via [make perf.opt.log] which
produces the graph explained {{:#performance}below}.

{2:running Running programs}

{3:compilation Compiling and linking}

Programs are compiled by specifying where Sundials/ML is installed, e.g.,
{ul
    {- [-I +sundialsml],}
    {- or [-I `opam config var lib`/sundialsml],}
    {- or [ocamlfind ... -package sundialsml],}}
and including [bigarray.cma] and [sundials.cma], for example:
{C {[ocamlc -o myprog.byte -I +sundialsml bigarray.cma sundials.cma myprog.ml]}}
or the [.cmxa] versions:
{C {[ocamlopt -o myprog.opt -I +sundialsml bigarray.cmxa sundials.cmxa myprog.ml]}}

The [sundials.cma/.cmxa] files link against the libraries
[libsundials_cvodes] and [libsundials_idas]. The code in these libraries
should give the same results as that in those without sensitivity analysis
(except for the functions {!Cvode.get_work_space} and {!Ida.get_work_space}),
even though they are compiled from distinct source files. The
[sundials_no_sens.cma/cmxa] files, on the other hand, link against the
libraries [libsundials_cvode] and [libsundials_ida] and thus do not include the
functionality in {!Cvodes} or {!Idas}. Both sets of files link against
[libsundials_kinsol] and [libsundials_nvecserial].

The parallel features—in the {!Nvector_parallel}, {!Cvode_bbd},
{!Cvodes_bbd}, {!Ida_bbd}, {!Idas_bbd}, and {!Kinsol_bbd} modules—require the
additional inclusions of [mpi.cma] and [sundials_mpi.cma]. So, for example:
{C {[ocamlc -o myprog.byte -I +sundialsml bigarray.cma mpi.cma sundials.cma sundials_mpi.cma myprog.ml]}}
or with the [.cmxa] versions:
{C {[ocamlopt -o myprog.opt -I +sundialsml bigarray.cmxa mpi.cmxa sundials.cmxa sundials_mpi.cmxa myprog.ml]}}
The [sundials_mpi.cma/.cmxa] files link against the
[libsundials_nvecparallel] library.

Under [ocamlfind], the sensitivity and parallel features
are selected via subpackages.  For example, for both:
{C {[ocamlfind ocamlopt -package sundialsml.mpi -linkpkg -o mysim.opt mysim.ml]}}
The available packages and the features they select are:
{ul
    {- [sundialsml]: sensitivity ON, parallel OFF,}
    {- [sundialsml.mpi]: sensitivity ON, parallel ON,}
    {- [sundialsml.no_sens]: sensitivity OFF, parallel OFF, and}
    {- [sundialsml.no_sens.mpi]: sensitivity OFF, parallel ON.}}

{3:toplevel From the toplevel}

Sundials/ML can also be used from the OCaml interactive loop, either by the
invocation:
{C {[ocaml bigarray.cma -I +sundialsml sundials.cma]}}
or through [ocamlfind], for example: {[
#use "topfind";;
#require "sundialsml";;

let f t y yd = yd.{0} <- 1.;;
let g t y gout = gout.{0} <- y.{0};;
let y = Sundials.RealArray.of_array [| -1.0 |];;
let yvec = Nvector_serial.wrap y;;
let s = Cvode.init Cvode.Adams Cvode.Functional Cvode.default_tolerances
		   f ~roots:(1, g) 0. yvec;;
Cvode.set_stop_time s 2.;;

(* repeat the commands below to advance the simulation until t = 2.0 *)
let (t', result) = Cvode.solve_normal s 2. yvec;;
Printf.printf "%e: " t';
Sundials.RealArray.iter (Printf.printf "\t%e") y;
Printf.printf "\n";;]}

Using parallel features from a toplevel is most cleanly done with [ocamlfind]
by first creating a custom toplevel:
{C [ocamlfind ocamlmktop -o partop -package sundialsml.mpi,findlib -linkpkg]}

and then launching it in multiple terminals:
{C [mpirun -np 2 xterm -e ./partop]}
Here, [2] is the number of processes, [xterm] is the terminal program, and
[-e ./partop] has each [xterm] execute [./partop].
As a simple test, paste the following into all terminals: {[
#use "topfind";;
#require "sundialsml.mpi";;

let comm = Mpi.comm_world
let n = Mpi.comm_size comm
let my_id = Mpi.comm_rank comm
let pv = Nvector_parallel.make 1 n comm (float_of_int (my_id + 1));;

Printf.printf "%d: local=%f.\n" my_id (Nvector_parallel.local_array pv).{0};;
Printf.printf "Sum of abs. = %f\n" (Nvector_parallel.Ops.n_vl1norm pv);;
]}

{3:solutions Solutions to common problems}

{ol
    {- The message
       {[Fatal error: cannot load shared library dllmlsundials]}
       can usually be fixed by updating [LD_LIBRARY_PATH], for example,
       {[export LD_LIBRARY_PATH=/usr/local/lib:${LD_LIBRARY_PATH}]}
       Otherwise you may have compiled Sundials without
       [--enable-shared]; see {{:#install}above}.}
}


{2:performance Performance}

An interface like Sundials/ML inevitably adds overhead: there is
extra code to execute at each call. But, how significant is this cost? And,
more broadly, how does the performance of OCaml compare to that of C for
programs that use numeric solvers?

These questions are not easy to answer. As a first attempt, we took the
examples in C from the Sundials distribution, reimplemented them in
OCaml and compared the execution times. The bars in the graph below show
the ratios of the execution times of the OCaml code to the C code, i.e., a
value of 2 on the left axis means that OCaml is twice as
slow. The black dots indicate, against the right axis, the execution
time of the C code.

{img perf.opt.png}

The graph suggests that the OCaml versions are rarely more than twice as
slow as the original ones and that they are often around or less than 50%
slower.
The [*_custom] example ({color #deebf7 light blue}) uses custom nvectors
with low-level operations in OCaml and the [*_alt] examples ({color #9ecae1
darker blue}) use linear solvers implemented in OCaml.

This conclusion seems reasonable as a first approximation, but several
details of the analysis process and individual results show that the real
situation is less clear-cut. For one, the running times of most of the
examples are so short that accurate profiling is not possible, i.e.,
{{:http://pubs.opengroup.org/onlinepubs/9699919799/utilities/time.html}time}
and {{:https://sourceware.org/binutils/docs/gprof/}gprof} simply show 0
seconds.
The figures in the graph were obtained by modifying the examples to
repeatedly execute their [main] functions.
The number of repetitions varies per example since otherwise the slower
examples take too long.
The timings indicated by the dots and the axis at right are calculated by
dividing the wall-clock time of each C version by the number of repetitions.
All but six of the serial examples ({color #de2d26 red}) run so fast that 
comparisons are made based on tens, or usually hundreds of repetitions and
in some cases this amplifies factors other than the interface overhead.
For instance, OCaml versions (more so for versions before 4.02) spend a
significant fraction of their time in [printf], and we were able to lower
their ratios by instead using [print_string] and [print_int].

The parallel examples ({color #fc9272 lighter red}) all have relatively long
run times and results are obtained without iterating.
Their OCaml/C ratios are almost all close to 1—the interface and other
overheads are small compared to the dominating costs of parallelization and
communication.

We were able to make our OCaml versions much faster (up to 4 times) by:
{ul
    {- Adding explicit type annotations to all vector arguments.
       For instance, rather than declare a callback with
       {[ let f t y yd = ... ,]}
       it is better to use
       {[ let f t (y : Sundials.RealArray.t) (yd : Sundials.RealArray.t) = ... ,]}
       or more concisely
       {[ let f : Sundials.RealArray.t Cvode.rhsfn = fun t y yd -> ...]}
       since then the compiler need not generate polymorphic code and
       can optimize for the bigarray layout.}
    {- Avoid functions like
       {{:http://caml.inria.fr/pub/docs/manual-ocaml/libref/Bigarray.Array1.html#VALsub}[Bigarray.Array1.sub]}
       and
       {{:http://caml.inria.fr/pub/docs/manual-ocaml/libref/Bigarray.Array2.html#VALslice_left}[Bigarray.Array2.slice_left]}.
       These functions allocate new bigarrays on the major
       heap, which increases the frequency of major GCs. They can often be
       avoided by calculating and passing indices more explicitly.
       When part of an array must be passed to another function, it
       can be faster, depending on the size, to copy into and out of a
       statically-allocated temporary array.}
    {- Sequences of {!Sundials.RealArray2.get} and
       {!Sundials.RealArray2.set} operations are usually better replaced by
       {!Sundials.RealArray2.unwrap} (projection from a tuple) and direct
       accesses to the underlying array.}
    {- Write numeric expressions and loops according to the advice in
	{{:#refs}\[2\]}
       to avoid float ‘boxing’.}
}

In summary, OCaml code using the Sundials solvers should never be
more than twice as slow as the equivalent code written in C, provided the
guidelines above are followed, and it may sometimes only be 50%
slower. It is usually, however, faster to write and debug OCaml code thanks
to automatic memory management, bounds checking on arrays, strong static
type checking, higher-order functions, etcetera. Moreover, the Sundials/ML
library offers a good comprise for programs combining symbolic manipulation and
numeric calculation.

{2:refs References}

{div open class="references"}
{ol
  {- A. C. Hindmarsh, P. N. Brown, K. E. Grant, S. L. Lee, R. Serban,
     D. E. Shumaker, and C. S. Woodward,
     “{{:http://computation.llnl.gov/casc/nsde/pubs/toms_sundials.pdf}{b
      SUNDIALS: Suite of Nonlinear and Differential/Algebraic Equation
      Solvers}},” ACM Transactions on Mathematical Software, 31(3),
      pp. 363-396, 2005.}
  {- X. Leroy,
     “{{:http://caml.inria.fr/pub/old_caml_site/ocaml/numerical.html}{b Old
      Objective Caml site: Writing efficient numerical code in Objective
      Caml}},” July 2002.}
}
{div close}

{2:acks Acknowledgements}

We gratefully acknowledge the support of the
{{:https://itea3.org/project/modrio.html} ITEA 3 project 11004 MODRIO} (Model
driven physical systems operation), {{:http://www.inria.fr/}Inria}, and
the {{:http://www.di.ens.fr/}Departement d'Informatique de l'ENS}.

This library benefits greatly from the OCaml {{:http://caml.inria.fr/pub/docs/manual-ocaml/libref/Bigarray.html}Bigarray} and {{:https://forge.ocamlcore.org/projects/ocamlmpi/}MPI}
libraries, and from {{:https://ocaml.org/}OCaml}'s optimised floating-point
representations and compilation.

This documentation uses {{:http://www.xulforum.org}J. Protzenko}'s
{{:http://www.xulforum.org/files/ocamlcss/style.css}CSS stylesheet}, and
{{:http://www.mathjax.org}MathJax} for rendering mathematics.

We are grateful for direct contributions to this library from
{ul
    {- {{:http://gallium.inria.fr/~scherer/}G. Scherer}}
}

{2:indexes Indexes}

{!indexlist}
{div close}

